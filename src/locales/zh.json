{
  "senior_advice": "学长寄语：",
  "numpy_module": {
    "title": "1. 内存切片可视化 (4x4 Matrix)",
    "view_label": "View (Reference)",
    "view_desc": "Basic Slicing 总是返回视图。修改它会直接改变原矩阵内存！",
    "fancy_label": "Copy (New Memory)",
    "fancy_desc": "Fancy Indexing 创建的是副本。这涉及到内存分配，大规模使用时效率较低。",
    "mask_label": "Copy (New Memory)",
    "mask_desc": "Boolean Mask 同样会触发内存复制。它是提取特定条件数据的神器。",
    "instruction": "选择一种切片方式观察 NumPy 的内存行为...",
    "broadcast_title": "2. 广播机制 (Broadcasting)",
    "broadcast_advice": "广播不是真的把数据在内存里复制，而是在遍历迭代器时虚拟地映射地址。核心准则：从最后一位往前对，要么相等，要么其中一个是 <1>1</1>。",
    "fancy_btn": "a[[0, 2]]",
    "mask_btn": "a[a % 2 == 0]",
    "slice_btn": "a[1:2, :]"
  },
  "backprop_module": {
    "title": "链式法则追踪器",
    "output_layer": "Output Layer",
    "error_val": "误差值",
    "calculating": "正在推导梯度...",
    "track_grad": "追踪梯度 Δwjk",
    "notebook_title": "推导笔记本 (COMP2211 Core)",
    "step1_title": "Step 1: 链式法则展开",
    "step2_title": "Step 2: 定义误差项 (Error Signal)",
    "step2_desc": "令 <1>\\delta_k = - \\frac{\\partial E}{\\partial net_k}</1>。在 MSE 损失下：",
    "step3_title": "Step 3: 权重更新量",
    "advice": "记住，反向传播本质上是『寻找罪魁祸首』的过程。每一层权重 <1>w_{jk}</1> 都在问：误差 <3>E</3> 有多少是由我负责的？<5>\\delta_k</5> 就是上一层传回来的『责备信』。"
  },
  "kernel_module": {
    "operation": "Operation:",
    "input_image": "Input Image",
    "kernel": "Kernel",
    "output_feature_map": "Output Feature Map",
    "advice": "卷积核本质上是一个局部特征过滤器。当你使用 <1>\\text{Laplacian}</1> 算子时，它在做二阶导数近似，能迅速捕捉到像素亮度的『突变点』。"
  },
  "bayes": {
    "basics": {
      "title": "1. 贝叶斯法则的核心解析",
      "terms": {
        "posterior": "Posterior (后验概率)",
        "posterior_desc": "已知证据 <1>E</1> 发生后，我们对信念 <3>B</3> 的更新程度。",
        "prior": "Prior (先验概率)",
        "prior_desc": "在看到任何证据之前，信念 <1>B</1> 本身发生的概率。",
        "likelihood": "Likelihood (似然概率)",
        "likelihood_desc": "假设信念 <1>B</1> 为真，证据 <3>E</3> 出现的可能性。",
        "marginal": "Marginal (边际概率)",
        "marginal_desc": "证据 <1>E</1> 在所有情况下发生的总概率。"
      }
    },
    "fire_case": {
      "title": "2. 实战演练：烟雾与火警案例 (Notes P.15)",
      "p_fire": "火灾概率 <1>P(\\text{Fire})</1>",
      "p_smoke": "烟雾概率 <1>P(\\text{Smoke})</1>",
      "p_smoke_given_fire": "火灾产烟 <1>P(\\text{Smoke}|\\text{Fire})</1>",
      "advice": "讲义中的经典案例：虽然火灾很少见（Prior = 1%），但烟雾可能因为BBQ而常见（Marginal = 10%）。贝叶斯法则告诉我们，此时看到烟雾并确定火灾的概率只有 <1>9\\%</1>。 <3>证据不等于结论，先验概率非常重要！</3>",
      "result_title": "看到烟雾后火灾的概率",
      "calc_process": "计算过程："
    },
    "naive": {
      "input_title": "特征输入",
      "smoothing": "平滑系数 <1>\\alpha</1>:",
      "log_mode": "对数求和模式",
      "product_mode": "连乘积模式",
      "result_title": "分类结果 (讲义 P.29)",
      "likelihood_chain": "似然概率链",
      "prob_for": "{{cls}} 类别的概率项",
      "advice": "讲义 P.23 重点：贝叶斯之所以『朴素』，是因为假设特征之间 <1>条件独立</1>。这对垃圾邮件过滤很有效。注意 <3>零频率问题</3>，尝试增大 <5>\\alpha</5> 看看变化！"
    }
  },
  "knn": {
      "click_instruction": "点击背景移动测试点",
      "raw_data": "原始数据",
      "standardized": "标准化",
      "test_sample": "测试样本",
      "model_complexity": "模型复杂度 vs 错误率",
      "low_k": "低 K 值",
      "overfitting": "过拟合",
      "high_k": "高 K 值",
      "underfitting": "欠拟合",
      "voting_panel": "分类投票面板",
      "k_value": "参数 K 值:",
      "m_vote": "M 码投票",
      "l_vote": "L 码投票",
      "advice": "仔细观察交互变化：当你增大 <1>K</1> 值时，决策边界会变得更加平滑。较小的 <1>K</1> 会导致边界复杂且容易 <3>过拟合</3>（捕捉到噪声），而过大的 <5>K</5> 则会过度简化边界导致 **欠拟合**。另外，尝试切换『标准化』模式，看看量纲如何影响距离计算——如果不进行标准化，数值范围大的特征（如体重）将主导距离计算，这是 KNN 中最经典的陷阱！"
    },
  "app": {
    "title": "CS/AI 交互式学习实验室",
    "subtitle": "COMP2211 Machine Learning Notebook",
    "version": "v2.0 Katex Enhanced",
    "tabs": {
      "knn": "K-近邻算法",
      "bayesBasics": "贝叶斯基础",
      "naiveBayes": "朴素贝叶斯",
      "numpy": "NumPy 机制",
      "backprop": "反向传播",
      "kernel": "卷积核实验室"
    },
    "section": {
      "bayesBasics": {
        "title": "贝叶斯定理基础",
        "subtitle": "从数学定义到直觉更新"
      },
      "naiveBayes": {
        "title": "朴素贝叶斯推断",
        "subtitle": "特征条件独立假设下的分类器"
      },
      "knn": {
        "title": "K-近邻算法",
        "subtitle": "距离度量与决策边界"
      },
      "numpy": {
        "title": "NumPy 内部机制",
        "subtitle": "深入内存地址映射与广播逻辑"
      },
      "backprop": {
        "title": "反向传播与梯度更新",
        "subtitle": "链式法则是连接误差与权重的桥梁"
      },
      "kernel": {
        "title": "卷积核实验室",
        "subtitle": "实时模拟空间滤波器如何提取边缘特征"
      }
    },
    "sidebar": {
      "knowledge_core": "Knowledge Core",
      "exam_tip": {
        "title": "Exam Tip",
        "content": "考试注意：<1>Broadcasting</1> 只能扩展 Size 为 1 的维度。<3>A \\cdot B</3> (np.dot) 和 <5>A \\odot B</5> (Element-wise) 物理含义完全不同！"
      }
    },
    "footer": {
      "copyright": "© 2026 KnowIt COMP2211 ML Learning Lab. Education through interaction.",
      "latency": "Latency: 12ms",
      "render": "Render: KaTeX High-Def"
    }
  }
}
